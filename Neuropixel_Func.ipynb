{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__iTnZRKuVd_"
      },
      "outputs": [],
      "source": [
        "def access_trash():\n",
        "  # First, authorize access to the Google Drive API\n",
        "  from google.colab import auth\n",
        "  from googleapiclient.discovery import build\n",
        "  from googleapiclient.errors import HttpError\n",
        "\n",
        "  auth.authenticate_user()\n",
        "  drive_service = build('drive', 'v3')\n",
        "\n",
        "  # Define the ID of the Trash folder\n",
        "  trash_folder_id = 'trash'\n",
        "\n",
        "  # Define the query to retrieve the files in the Trash folder\n",
        "  query = \"trashed=true\"\n",
        "\n",
        "  try:\n",
        "    # Call the Drive API to retrieve the files in the Trash folder\n",
        "    files = drive_service.files().list(q=query, spaces='drive').execute().get('files', [])\n",
        "\n",
        "    # Iterate over the files in the Trash folder and delete them\n",
        "    for file in files:\n",
        "      try:\n",
        "        drive_service.files().delete(fileId=file['id']).execute()\n",
        "        print(f\"File {file['name']} deleted from Trash folder.\")\n",
        "      except HttpError as error:\n",
        "        print(f\"An error occurred: {error}\")\n",
        "  except HttpError as error:\n",
        "    print(f\"An error occurred: {error}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm79C92nIQp5"
      },
      "outputs": [],
      "source": [
        "!pip install allensdk\n",
        "import allensdk\n",
        "print(allensdk.__version__)\n",
        "\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Tr8K7DRSI4PL",
        "outputId": "ba323d8b-6532-47e8-e588-df8d7331fb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import allensdk\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.collections import LineCollection\n",
        "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.gridspec as gridspec\n",
        "import umap.umap_ as umap\n",
        "\n",
        "from allensdk.brain_observatory.behavior.behavior_project_cache.\\\n",
        "    behavior_neuropixels_project_cache \\\n",
        "    import VisualBehaviorNeuropixelsProjectCache\n",
        "\n",
        "output_dir = './'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive\n",
        "\n",
        "cache = VisualBehaviorNeuropixelsProjectCache.from_s3_cache(\n",
        "            cache_dir=Path(output_dir))\n",
        "ecephys_sessions_table = cache.get_ecephys_session_table()\n",
        "#ecephys_sessions_table.head()\n",
        "''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iywO3Q57JA4C"
      },
      "outputs": [],
      "source": [
        "def data(ecephy_session_id):\n",
        "\n",
        "  #each session has tow session id, one is ecephy_session_id, one is behavior_session_id\n",
        "  session = cache.get_ecephys_session(ecephys_session_id=ecephy_session_id)\n",
        "\n",
        "  units = session.get_units()\n",
        "  channels = session.get_channels()\n",
        "  #same units with more columns, so we can seprate them based on more features\n",
        "  unit_channels = units.merge(channels, left_on='peak_channel_id', right_index=True)\n",
        "\n",
        "  #first let's sort our units by depth\n",
        "  unit_channels = unit_channels.sort_values('probe_vertical_position', ascending=False)\n",
        "\n",
        "  #now we'll filter them\n",
        "  good_unit_filter = ((unit_channels['snr']>1)&\n",
        "                    (unit_channels['isi_violations']<1)&\n",
        "                    (unit_channels['firing_rate']>0.1))\n",
        "\n",
        "  good_units = unit_channels.loc[good_unit_filter]\n",
        "  print(len(units)-len(good_units), 'was removed due to bad conditions, not sure is a good idea')\n",
        "  spike_times = session.spike_times\n",
        "\n",
        "  stimulus_presentations = session.stimulus_presentations\n",
        "  change_times = stimulus_presentations[stimulus_presentations['active']&\n",
        "                            stimulus_presentations['is_change']]['start_time'].values\n",
        "\n",
        "  return unit_channels,spike_times,change_times\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoCAzuwPK6ei"
      },
      "outputs": [],
      "source": [
        "#Convenience function to compute the PSTH(histograms of the times at which neurons fire)\n",
        "def makePSTH(spikes, startTimes, windowDur, binSize=0.001):\n",
        "    bins = np.arange(0,windowDur+binSize,binSize)\n",
        "    counts = np.zeros(bins.size-1)\n",
        "    for i,start in enumerate(startTimes):\n",
        "        startInd = np.searchsorted(spikes, start)\n",
        "        endInd = np.searchsorted(spikes, start+windowDur)\n",
        "        counts = counts + np.histogram(spikes[startInd:endInd]-start, bins)[0]\n",
        "    \n",
        "    counts = counts/startTimes.size\n",
        "    return counts/binSize, bins\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_AXnYiIK9Xa"
      },
      "outputs": [],
      "source": [
        "#area_of_interest = 'VISp'\n",
        "\n",
        "def binned_spike(area_of_interest,unit_channels,spike_times,change_times):\n",
        "\n",
        "  if area_of_interest not in unit_channels.value_counts('structure_acronym'):\n",
        "    return 0\n",
        "    \n",
        "  area_change_responses = []\n",
        "  #here instead of good units(units with high filter we used units channels which is all the units)\n",
        "  area_units = unit_channels[unit_channels['structure_acronym']==area_of_interest]\n",
        "  #print((area_units.index))\n",
        "\n",
        "  time_before_change = 1\n",
        "  duration = 2.5\n",
        "  for iu, unit in area_units.iterrows():\n",
        "      unit_spike_times = spike_times[iu]\n",
        "      unit_change_response, bins = makePSTH(unit_spike_times, \n",
        "                                            change_times-time_before_change, \n",
        "                                            duration, binSize=0.01)\n",
        "      area_change_responses.append(unit_change_response)\n",
        "  area_change_responses = np.array(area_change_responses)\n",
        "\n",
        "  return area_change_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ddZefqOtlU"
      },
      "outputs": [],
      "source": [
        "#make it a func to call it severl \n",
        "def pca_plot2d(com_n, data,path):\n",
        "\n",
        "  pca = PCA(n_components=com_n)\n",
        "  pca_spike = pca.fit_transform(data)\n",
        "  col=np.arange(0,len(data)) #the time binned\n",
        "  #colormap\n",
        "  cmap = mpl.cm.Reds\n",
        "  norm = mpl.colors.Normalize(vmin=0, vmax=250)\n",
        "\n",
        "  # Create a 2D scatter plot \n",
        "  fig, ax = plt.subplots()\n",
        "  sc = ax.scatter(pca_spike[:,0], pca_spike[:,1],c = cmap(norm(col)))\n",
        "  # Connect the dots with a line\n",
        "  points = np.array([pca_spike[:,0], pca_spike[:,1]]).T.reshape(-1, 1, 2)\n",
        "  segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
        "  lc = LineCollection(segments, cmap='Reds')\n",
        "  lc.set_array(col)\n",
        "  ax.add_collection(lc)\n",
        "\n",
        "  dx = np.diff(pca_spike[:,0])\n",
        "  dy = np.diff(pca_spike[:,1])\n",
        "  cmap = mpl.cm.get_cmap('Reds') # choose a color map\n",
        "  colors = cmap(np.linspace(0, 1, len(dx))) # generate colors for each arrow based on dx\n",
        "\n",
        "  for i in range(len(dx)):\n",
        "      ax.annotate('', xy=(pca_spike[:,0][i+1], pca_spike[:,1][i+1]), xytext=(pca_spike[:,0][i], pca_spike[:,1][i]),\n",
        "                  arrowprops=dict(arrowstyle='->', color=colors[i]))\n",
        "\n",
        "  plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap))\n",
        "  plt.xlabel(\"PC1\")\n",
        "  plt.ylabel(\"PC2\")\n",
        "  plt.title(\"PCA_\"+area_of_interest)\n",
        "  plt.savefig(path+\"/PCA_Plot2d\")\n",
        "  plt.close()\n",
        "\n",
        "  return pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHbuiAI8Ou2B"
      },
      "outputs": [],
      "source": [
        "#make it a func to call it for all regions\n",
        "def pca_plot3d(com_n, data,name,path,f=0,ax=None):\n",
        "\n",
        "  pca = PCA(n_components=com_n)\n",
        "  pca_spike = pca.fit_transform(data)\n",
        "  col=np.arange(0,len(data)) #the time binned\n",
        "  #colormap\n",
        "  cmap = mpl.cm.Reds\n",
        "  norm = mpl.colors.Normalize(vmin=0, vmax=250)\n",
        "\n",
        "  # Create a 3D axes object pc1,pc2,pc3\n",
        "  if f==0:\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = fig.add_subplot( projection='3d')\n",
        "\n",
        "  ax.scatter(pca_spike[:,0], pca_spike[:,1], pca_spike[:,2],c = mpl.cm.cool(norm(col)))\n",
        "\n",
        "\n",
        "  points = np.array([pca_spike[:,0], pca_spike[:,1], pca_spike[:,2]]).T.reshape(-1, 1, 3)\n",
        "  segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
        "  lc = Line3DCollection(segments, cmap='cool')\n",
        "  lc.set_array(col)\n",
        "  ax.add_collection(lc)\n",
        "\n",
        "  if f==0:\n",
        "    ax.set_xlabel('PC1')\n",
        "    ax.set_ylabel('PC2')\n",
        "    ax.set_zlabel('PC3')\n",
        "    ax.set_title('3D PCA_' + name + '_vs Time')\n",
        "\n",
        "  plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.cool),fraction=0.025, pad=0.02)\n",
        "  if f==0:\n",
        "    plt.savefig(path+\"/PCA_Plot3d\")\n",
        "\n",
        "  #plt.show()\n",
        "  return pca.explained_variance_ratio_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1nuLGogIpmqg"
      },
      "outputs": [],
      "source": [
        "def umap_plot3d(com_n,n_neigh,min_dist,data,name,path,f=0,ax=None): \n",
        "  \n",
        "  np.random.seed(123)\n",
        "  umap_model = umap.UMAP(n_components=com_n, n_neighbors=n_neigh, min_dist=min_dist)\n",
        "  embedding = umap_model.fit_transform(data)\n",
        "\n",
        "  col=np.arange(0,len(data)) #the time binned\n",
        "  cmap = mpl.cm.Reds\n",
        "  norm = mpl.colors.Normalize(vmin=0, vmax=250)\n",
        "\n",
        "  if f==0:\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = fig.add_subplot( projection='3d')\n",
        "    \n",
        "  ax.scatter( embedding[:,0], embedding[:,1],embedding[:,2],c = mpl.cm.Reds(norm(col)))\n",
        "  if f==0:\n",
        "    ax.set_xlabel('UMAP 1')\n",
        "    ax.set_ylabel('UMAP 2')\n",
        "    ax.set_zlabel('UMAP 3')\n",
        "    ax.set_title('UMAP Embeddings_'+ name)\n",
        "\n",
        "  plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Reds),fraction=0.025, pad=0.02)\n",
        "  if f==0:\n",
        "    plt.savefig(path+\"/Umap_Plot3d\")\n",
        "\n",
        "  #for combined data\n",
        "  '''\n",
        "  if f==2:\n",
        "    fig = plt.figure(figsize=(10, 8))\n",
        "    ax = fig.add_subplot( projection='3d')\n",
        "    ax.scatter( embedding[:,0], embedding[:,1],embedding[:,2],c = mpl.cm.Reds(norm(col)))\n",
        "    plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Reds),fraction=0.025, pad=0.02)\n",
        "    plt.savefig(path+'Umap_All region')\n",
        "  '''\n",
        "    \n",
        "  #plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDbfI-wvfU0o"
      },
      "outputs": [],
      "source": [
        "id=1044385384\n",
        "#unit_channels,spike_times,change_times = data(session_id)\n",
        "#path= \"/content/gdrive/My Drive/Results_neuropixel/Familiar/Umap_all\" + str(session_id)\n",
        "com_n=5\n",
        "#for umap\n",
        "n_neigh=5\n",
        "min_dist=0.05\n",
        "\n",
        "path= '/content/gdrive/My Drive/Results_neuropixel/Familiar'\n",
        "reg=[]\n",
        "all_data=[]\n",
        "path = os.path.join(path, str(id))\n",
        "# Loop through all the files in the directory and read them one by one\n",
        "for file_name in os.listdir(path):\n",
        "  if file_name.endswith('.npy'):\n",
        "    file_path = os.path.join(path, file_name)\n",
        "    data = np.load(file_path)\n",
        "    reg.append(str(os.path.splitext(file_name)[0]))\n",
        "    all_data.append(data)\n",
        "\n",
        "all_inone = [item for sublist in all_data for item in sublist]\n",
        "\n",
        "path= '/content/gdrive/My Drive/Results_neuropixel/Familiar/Umap_combined_data'  \n",
        "path = os.path.join(path, str(id))\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "umap_plot3d(com_n,n_neigh,min_dist,all_inone,('Umap_All region' +str(id)),path)\n",
        "\n",
        "\n",
        "'''\n",
        "#not needing this func anymore\n",
        "#need to change the description of function\n",
        "def combined_data(com_n,n_neigh,min_dist,path,data):\n",
        "def combined_data(com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times):\n",
        "  reg = ['VISp', 'VISpm', 'VISal', 'VISrl', 'VISl', 'VISam']\n",
        "  all=[]\n",
        "\n",
        "  for i in range(len(reg)):\n",
        "    area_change_responses=binned_spike(reg[i],unit_channels,spike_times,change_times)\n",
        "    all.append(area_change_responses)\n",
        "  \n",
        "  all_inone = [item for sublist in all for item in sublist]\n",
        "  #all= all.reshape()\n",
        "  #pca_plot3d(com_n, all_inone,'PCA_All region',path)\n",
        "  #f==2 for combined data\n",
        "  umap_plot3d(com_n,n_neigh,min_dist,all_inone,'Umap_All region',path,2)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH9qFbUuutYA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#need to be run on;y once, is Done for now\n",
        "#preprocess the data , seprate the data of each region and save it in google drive so it wont take too long each time for analysis\n",
        "#first for family session then for novel session\n",
        "\n",
        "session_ids= ecephys_sessions_table.loc[(ecephys_sessions_table[\"experience_level\"]=='Novel') & (ecephys_sessions_table[\"session_number\"]==2)].index\n",
        "\n",
        "savepath= \"/content/gdrive/My Drive/Results_neuropixel/Novel\"\n",
        "reg = ['VISp', 'VISpm', 'VISal', 'VISrl', 'VISl', 'VISam']\n",
        "\n",
        "#it has some problem catching 1047977240 this session, before it was ok :|\n",
        "for id in session_ids:\n",
        "  path=os.path.join(savepath, str(id))\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  #os.makedirs(path)\n",
        "  unit_channels,spike_times,change_times= data(id)\n",
        "  for region in reg:\n",
        "    reg_path = os.path.join(path, region)\n",
        "    #if not os.path.exists(reg_path):\n",
        "      #os.makedirs(reg_path)\n",
        "    #construct the data for each reg\n",
        "    area_change_responses= binned_spike(region,unit_channels,spike_times,change_times)\n",
        "    if type(area_change_responses)==int:\n",
        "      continue\n",
        "    np.save(reg_path, area_change_responses)\n",
        "\n",
        "  os.remove(\"./visual-behavior-neuropixels-0.4.0/behavior_ecephys_sessions/\"+str(id)+\"/ecephys_session_\"+str(id)+\".nwb\")\n",
        "  access_trash()\n",
        "'''\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaUnTcLLP5tv"
      },
      "outputs": [],
      "source": [
        "#compatible plot3D function to be used with gridspace\n",
        "com_n=5\n",
        "#for umap\n",
        "n_neigh=15\n",
        "min_dist=0.1\n",
        "#path= \"/content/gdrive/My Drive/Results_neuropixel\"\n",
        "#unit_channels,spike_times,change_times= data(1048189115)\n",
        "#area_change_responses= binned_spike(area_of_interest,unit_channels,spike_times,change_times)\n",
        "#def plot3d_forgridspec(method_name,com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times):\n",
        "\n",
        "def plot3d_forgridspec(method_name,com_n,n_neigh,min_dist,path,data,reg):\n",
        "\n",
        "    #reg = ['VISp', 'VISpm', 'VISal', 'VISrl', 'VISl', 'VISam']\n",
        "    var=[]\n",
        "    delt=[]\n",
        "    var_s=[]\n",
        "    #all=[]\n",
        "    fig = plt.figure(figsize=(40,30))\n",
        "    gs = fig.add_gridspec(len(reg), 2, width_ratios=[1,8], wspace=0.01)\n",
        "    fig.subplots_adjust(wspace=0.05, hspace=0.1, left=0.1, right=0.25, top=0.95, bottom=0.1)\n",
        "    #pca_plot3d(com_n, data,name,path,f=0,ax=None)\n",
        "    #umap_plot3d(n_com,n_neigh,min_dist,data,name,path,f=0,ax=None)\n",
        "\n",
        "\n",
        "# Set the path to the directory containing the files\n",
        "\n",
        "\n",
        "    for i in range(len(reg)):\n",
        "        ax = fig.add_subplot(gs[i, 1], projection='3d')\n",
        "        #area_change_responses=binned_spike(reg[i],unit_channels,spike_times,change_times)\n",
        "        #all.append(area_change_responses)\n",
        "        #if type(area_change_responses)==int:\n",
        "          #delt.append(reg[i])\n",
        "          #continue\n",
        "\n",
        "        if(method_name=='pca'):\n",
        "          var.append(pca_plot3d(com_n, data[i].T, reg[i],path,1,ax))\n",
        "          ax.set_xlabel('PC1' )\n",
        "          ax.set_ylabel('PC2' )\n",
        "          ax.set_zlabel('Time')\n",
        "          ax.set_title('PCA_'+ reg[i])\n",
        "\n",
        "        if(method_name=='umap'):\n",
        "          umap_plot3d(com_n,n_neigh,min_dist, data[i].T, reg[i],path,1, ax)\n",
        "          ax.set_xlabel('Embedding 1' )\n",
        "          ax.set_ylabel('Embedding 2' )\n",
        "          ax.set_zlabel('Embedding 3')\n",
        "          ax.set_title('UMAP Embeddings_'+ reg[i])\n",
        "        #ax = None # set the ax object to None to avoid conflict\n",
        "        \n",
        "    #print(len(delt))\n",
        "    #if len(delt)==1:\n",
        "      #reg.remove(delt[0])\n",
        "    #if len(delt)>1 :\n",
        "      #reg.remove(delt)\n",
        "    \n",
        "    \n",
        "    if(method_name=='pca'):\n",
        "      ax = fig.add_subplot(gs[:, 0])\n",
        "      var_s=(sum(np.array(var).T))\n",
        "      ax.plot(np.flip(var_s),np.flip(np.array(reg)),c='orange',marker='o')\n",
        "      ax.set_xlabel('Sum_3PC_Variance')\n",
        "      plt.xlim([0.6, 1])\n",
        "      ax.set_title('3D PCA_vs Time')\n",
        "    \n",
        "    if(method_name=='pca'):\n",
        "      plt.savefig(path+\"/PCA_Plot3d_All\")\n",
        "\n",
        "    if(method_name=='umap'):\n",
        "      plt.savefig(path+\"/Umap_Plot3d_All\")\n",
        "\n",
        "\n",
        "#plot3d_forgridspec('pca',com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times)\n",
        "#plot3d_forgridspec('umap',com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times)\n",
        "#pca_plot3d(3, area_change_responses.T,'VISp',path,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ocsRR4D9QAy3"
      },
      "outputs": [],
      "source": [
        "#ecephys_sessions_table.loc[(ecephys_sessions_table[\"experience_level\"]=='Novel') & (ecephys_sessions_table[\"session_number\"]==2)].index\n",
        "#plot3d_forgridspec(method_name,com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times)\n",
        "\n",
        "\n",
        "session_ids = ecephys_sessions_table.loc[(ecephys_sessions_table[\"experience_level\"]=='Familiar') & (ecephys_sessions_table[\"session_number\"]==1)].index\n",
        "#print(type(session_ids))\n",
        "session_ids=list(session_ids)\n",
        "session_ids.remove([1047977240,1093642839,1095138995])\n",
        "#cannot find this session data too ---> 1047977240, 1093642839 and 1095138995\n",
        "\n",
        "com_n=5\n",
        "#for umap\n",
        "n_neigh=15\n",
        "min_dist=0.1\n",
        "\n",
        "\n",
        "for id in session_ids:\n",
        "  path= '/content/gdrive/My Drive/Results_neuropixel/Familiar'\n",
        "  reg=[]\n",
        "  all_data=[]\n",
        "  path = os.path.join(path, str(id))\n",
        "# Loop through all the files in the directory and read them one by one\n",
        "  for file_name in os.listdir(path):\n",
        "    if file_name.endswith('.npy'):\n",
        "      file_path = os.path.join(path, file_name)\n",
        "      data = np.load(file_path)\n",
        "      reg.append(str(os.path.splitext(file_name)[0]))\n",
        "      all_data.append(data)\n",
        "\n",
        "  path= '/content/gdrive/My Drive/Results_neuropixel/Familiar/PCA'\n",
        "  savepath = os.path.join(path, str(id))\n",
        "  if not os.path.exists(savepath):\n",
        "    os.makedirs(savepath)\n",
        "  #pca_plot3d(com_n, data.T,str(file_name),path,f=0)\n",
        "  plot3d_forgridspec('pca',com_n,n_neigh,min_dist,savepath,all_data,reg)\n",
        "\n",
        "\n",
        "  path= '/content/gdrive/My Drive/Results_neuropixel/Familiar/UMAP'\n",
        "  savepath = os.path.join(path, str(id))\n",
        "  if not os.path.exists(savepath):\n",
        "    os.makedirs(savepath)\n",
        "  plot3d_forgridspec('umap',com_n,n_neigh,min_dist,savepath,all_data,reg)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIv-wknAW7o0"
      },
      "outputs": [],
      "source": [
        "#the same code for Novel sessions\n",
        "\n",
        "session_ids = ecephys_sessions_table.loc[(ecephys_sessions_table[\"experience_level\"]=='Novel') & (ecephys_sessions_table[\"session_number\"]==2)].index\n",
        "session_ids=list(session_ids)\n",
        "\n",
        "com_n=5\n",
        "#for umap\n",
        "n_neigh=15\n",
        "min_dist=0.1\n",
        "\n",
        "\n",
        "for id in session_ids:\n",
        "  path= '/content/gdrive/My Drive/Results_neuropixel/Novel'\n",
        "  reg=[]\n",
        "  all_data=[]\n",
        "  path = os.path.join(path, str(id))\n",
        "# Loop through all the files in the directory and read them one by one\n",
        "  for file_name in os.listdir(path):\n",
        "    if file_name.endswith('.npy'):\n",
        "      file_path = os.path.join(path, file_name)\n",
        "      data = np.load(file_path)\n",
        "      reg.append(str(os.path.splitext(file_name)[0]))\n",
        "      all_data.append(data)\n",
        "\n",
        "  path= '/content/gdrive/My Drive/Results_neuropixel/Novel/PCA'\n",
        "  savepath = os.path.join(path, str(id))\n",
        "  if not os.path.exists(savepath):\n",
        "    os.makedirs(savepath)\n",
        "  #pca_plot3d(com_n, data.T,str(file_name),path,f=0)\n",
        "  plot3d_forgridspec('pca',com_n,n_neigh,min_dist,savepath,all_data,reg)\n",
        "\n",
        "\n",
        "  path= '/content/gdrive/My Drive/Results_neuropixel/Novel/UMAP'\n",
        "  savepath = os.path.join(path, str(id))\n",
        "  if not os.path.exists(savepath):\n",
        "    os.makedirs(savepath)\n",
        "  plot3d_forgridspec('umap',com_n,n_neigh,min_dist,savepath,all_data,reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbAjmZk4U_vj"
      },
      "outputs": [],
      "source": [
        "#The code for when you want to directly download the data and preprocess yourself and then use it.\n",
        "'''\n",
        "exp_var=[]\n",
        "com_n=5\n",
        "#for umap\n",
        "n_neigh=15\n",
        "min_dist=0.1\n",
        "area_of_interest = 'VISrl'\n",
        "savepath= \"/content/gdrive/My Drive/Results_neuropixel\"\n",
        "\n",
        "\n",
        "\n",
        "for id in session_ids:\n",
        "  path=os.path.join(savepath, str(id))\n",
        "  if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "  #os.makedirs(path)\n",
        "  unit_channels,spike_times,change_times= data(id)\n",
        "  area_change_responses= binned_spike(area_of_interest,unit_channels,spike_times,change_times)\n",
        "  #if the area_of_interest is not in the data in does not compute for that specific session.\n",
        "  if type(area_change_responses)==int:\n",
        "    continu\n",
        "  exp_var.append(pca_plot2d(com_n, area_change_responses.T,path))\n",
        "  pca_plot3d(com_n, area_change_responses.T,area_of_interest,path)\n",
        "  plot3d_forgridspec('pca',com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times)\n",
        "  plot3d_forgridspec('umap',com_n,n_neigh,min_dist,path,unit_channels,spike_times,change_times)\n",
        "  os.remove(\"./visual-behavior-neuropixels-0.4.0/behavior_ecephys_sessions/\"+str(id)+\"/ecephys_session_\"+str(id)+\".nwb\")\n",
        "  access_trash()\n",
        "\n",
        "np.savetxt(savepath+\"/explained_variance\",exp_var,delimiter=\",\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOwKr-tIcwb5"
      },
      "outputs": [],
      "source": [
        "#find the sessions for same mouse in order to compare them through time.\n",
        "#for furthur analysis in the future\n",
        "'''\n",
        "mouse_id=ecephys_sessions_table['mouse_id']\n",
        "grouped = ecephys_sessions_table.groupby('mouse_id').groups\n",
        "\n",
        "ecephy_mouse=[]\n",
        "for i in mouse_id:\n",
        "  ecephy_mouse.append(grouped[i])\n",
        "\n",
        "ecephy_mouse=list(set(tuple(x) for x in ecephy_mouse))\n",
        "print(ecephy_mouse)\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}